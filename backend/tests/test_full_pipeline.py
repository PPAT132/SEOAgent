#!/usr/bin/env python3
"""
Test Full SEO Analysis Pipeline
Step-by-step test of each component, writing intermediate outputs to files.
"""

import os
import sys
import json
from pathlib import Path

script_path = Path(__file__).resolve()
project_root = script_path.parent.parent
sys.path.insert(0, str(project_root))

print(f"DEBUG: script file: {__file__}")
print(f"DEBUG: project root: {project_root}")
print(f"DEBUG: sys.path: {sys.path}")

try:
    from app.services.seo_analysis_service import SEOAnalysisService
    from app.core.lhr_parser import LHRTool
    from app.core.matcher import match_issues
    from app.core.issue_merger import transform_to_simple_issues_with_insertions
except ImportError as e:
    print(f"âŒ Import failed: {e}")
    print(f"CWD: {os.getcwd()}")
    print(f"sys.path: {sys.path}")
    print(f"project_root: {project_root}")
    sys.exit(1)

def save_json_file(data, filename, description):
    """Save a Python object as JSON file."""
    output_dir = Path(__file__).parent / "pipeline_outputs"
    output_dir.mkdir(exist_ok=True)
    
    filepath = output_dir / filename
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"âœ… {description} saved to: {filepath}")
    return filepath

def test_full_pipeline():
    """Run the full SEO analysis pipeline."""
    
    # 1. è¯»å–æµ‹è¯•HTMLæ–‡ä»¶
    print("ğŸ“– Reading test HTML file...")
    html_file_path = Path(__file__).parent / "test_seo_page.html"
    
    if not html_file_path.exists():
        print(f"âŒ HTML file not found: {html_file_path}")
        return
    
    with open(html_file_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"âœ… HTML loaded, length: {len(html_content)} chars")
    
    # 2. è°ƒç”¨LighthouseæœåŠ¡
    print("\nğŸ” Step 1: call Lighthouse service...")
    try:
        seo_service = SEOAnalysisService()
        lighthouse_result = seo_service._call_lighthouse_service(html_content)
        
        save_json_file(
            lighthouse_result, 
            "01_lighthouse_raw.json", 
            "Lighthouse raw result"
        )
        
        print(f"âœ… Lighthouse call OK, SEO score: {lighthouse_result.get('seoScore', 'N/A')}")
        
    except Exception as e:
        print(f"âŒ Lighthouse call failed: {e}")
        return
    
    # 3. è¿è¡ŒLHRè§£æå™¨
    print("\nğŸ“Š Step 2: run LHR parser...")
    try:
        parser = LHRTool()
        parsed_result = parser.parse_lhr_json(lighthouse_result)
        
        # ä¿å­˜è§£æåçš„ç»“æœ
        save_json_file(
            parsed_result, 
            "02_parser_output.json", 
            "LHR parser output"
        )
        
        print(f"âœ… Parser OK, issues: {len(parsed_result.get('issues', []))}")
        
    except Exception as e:
        print(f"âŒ Parser failed: {e}")
        return
    
    # 4. è¿è¡ŒåŒ¹é…å™¨
    print("\nğŸ¯ Step 3: run matcher...")
    try:
        matched_result = match_issues(html_content, parsed_result)
        
        # ä¿å­˜åŒ¹é…ç»“æœ
        save_json_file(
            matched_result, 
            "04_matcher_output.json", 
            "Matcher output"
        )
        
        matched_issues = matched_result.get('issues', [])
        matched_count = len([i for i in matched_issues if i.get('match_status') == 'matched'])
        print(f"âœ… Matcher OK, total issues: {len(matched_issues)}, matched: {matched_count}")
        
    except Exception as e:
        print(f"âŒ Matcher failed: {e}")
        return
    
    # 5. è¿è¡Œé—®é¢˜åˆå¹¶å™¨
    print("\nğŸ”§ Step 4: run issue merger...")
    try:
        merged_issues = transform_to_simple_issues_with_insertions(matched_result)
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        save_json_file(
            merged_issues, 
            "04_merger_output.json", 
            "Issue merger output"
        )
        
        print(f"âœ… Merger OK, merged issues: {len(merged_issues)}")
        
    except Exception as e:
        print(f"âŒ Merger failed: {e}")
        return
    
    # 6. æ„å»ºæœ€ç»ˆç»“æœ
    print("\nğŸ“ Step 5: build final result...")
    try:
        final_result = seo_service._build_final_result(
            parsed_result, 
            merged_issues, 
            html_content
        )
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        if hasattr(final_result, 'dict'):
            final_dict = final_result.dict()
        else:
            final_dict = final_result.__dict__
        
        save_json_file(
            final_dict, 
            "05_final_result.json", 
            "Final SEO analysis result"
        )
        
        print(f"âœ… Final result OK, SEO score: {final_dict.get('seo_score', 'N/A')}")
        
    except Exception as e:
        print(f"âŒ Final result failed: {e}")
        return
    
    print("\nğŸ‰ Full pipeline completed!")
    print("ğŸ“ Outputs saved under tests/pipeline_outputs/")
    print("\nğŸ“‹ Files:")
    print("  01_lighthouse_raw.json      - Lighthouse raw result")
    print("  02_parser_output.json       - LHR parser output")
    print("  03_matcher_output.json      - Matcher output")
    print("  04_merger_output.json       - Issue merger output")
    print("  05_final_result.json        - Final SEO analysis result")

if __name__ == "__main__":
    test_full_pipeline()

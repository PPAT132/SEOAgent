# LLM Tool - Core utility for language model interactions
import requests
import json

from typing import List

from ..config import Config
from app.schemas.seo_analysis import SEOAnalysisResult, IssueInfo

class LLMTool:
    """
    Core tool for interacting with Google's Generative AI API
    """
    
    def __init__(self):
        self.url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
        self.api_key = Config.GOOGLE_API_KEY
        self.validate_config()
    
    def validate_config(self):
        """Validate that required configuration is present"""
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required")
    
    def generate_content(self, prompt: str) -> str:
        """
        Generate content using Google's Generative AI API (Gemini)
        """
        try:
            # Use the correct Google Generative AI API endpoint and headers
            
            headers = {
                "Content-Type": "application/json",
                "X-goog-api-key": self.api_key
            }
            print("prompt: ", prompt)
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ]
            }
            print("making call to gemini...")
            response = requests.post(self.url, headers=headers, json=payload)
            
            if response.status_code != 200:
                response.raise_for_status()
            
            result = response.json()
            
            # Extract the generated content
            if "candidates" in result and len(result["candidates"]) > 0:
                generated_text = result["candidates"][0]["content"]["parts"][0]["text"]
                return generated_text.strip()
            else:
                raise Exception("No content generated by LLM")
                
        except Exception as e:
            raise e 
    
    # gets the html content
    def get_modification(self, modify_context: str, match_html: str, context: str) -> str:

        prompt = (
            f"Fix this HTML snippet for SEO:\n\n"
            f"Original: {match_html}\n"
            f"Issue: {modify_context}\n\n"
            f"Context: {context}\n\n"
            "Return ONLY the corrected HTML without markdown"
        )

        optimized_html = self.generate_content(prompt)
        return optimized_html
    
    # Process issues in batches to reduce context repetition
    def get_batch_modification(self, analysis_res: SEOAnalysisResult) -> SEOAnalysisResult:
        issues_list = analysis_res.issues
        batch_size = 10  # Process 10 issues per batch

        # Split issues: missing (insert new content) vs non-missing (replace/modify)
        # Only treat specific audit types as "missing" that require insertion
        missing_audit_ids = {"meta-description"}  # Conservative list - only confirmed missing types
        missing_issues = []
        non_missing_issues = []

        for issue in issues_list:
            # Check if this is a confirmed "missing" type (all ranges negative)
            ranges = issue.ranges or []
            is_missing = all(r[0] < 0 for r in ranges) if ranges else False
            
            # Double-check by audit_id or title to be safe
            is_missing_type = False
            if hasattr(issue, 'audit_id') and issue.audit_id in missing_audit_ids:
                is_missing_type = True
            elif 'meta description' in (issue.title or '').lower() and 'does not have' in (issue.title or '').lower():
                is_missing_type = True
            
            if is_missing and is_missing_type:
                missing_issues.append(issue)
            else:
                # Conservative: treat as non-missing if not confirmed
                non_missing_issues.append(issue)

        # Process non-missing issues in batches
        for i in range(0, len(non_missing_issues), batch_size):
            batch = non_missing_issues[i:i+batch_size]
            self.process_batch(batch, analysis_res.context, i//batch_size + 1)

        # Process missing issues with lightweight targeted prompts
        for issue in missing_issues:
            try:
                issue.optimized_html = self.generate_missing_element(issue, analysis_res.context)
            except Exception:
                # Fallback to raw_html suggestion if provided, else keep empty
                issue.optimized_html = issue.optimized_html or issue.raw_html

        return analysis_res

    def process_batch(self, batch_issues: List[IssueInfo], context: str, batch_num: int):
        """Process a batch of issues, sending context only once per batch"""
        
        # Build prompt containing issues with explicit output requirements
        batch_prompt = f"""
        Page Context:
        {context}

        You must fix exactly {len(batch_issues)} SEO issues. Return EXACTLY {len(batch_issues)} fixes in this EXACT format:

        ISSUE_1: [fixed HTML]
        ISSUE_2: [fixed HTML]
        ISSUE_3: [fixed HTML]
        ...
        ISSUE_{len(batch_issues)}: [fixed HTML]

        IMPORTANT RULES:
        - You MUST return exactly {len(batch_issues)} fixes
        - Each fix must start with "ISSUE_X:" followed by the corrected HTML
        - Return ONLY the corrected HTML, no explanations or markdown
        - Each fix must be on a separate line
        - The HTML must be valid and complete
        - For unknown images, put "UNKNOWN_IMAGE" as the alt tags

        Issues to fix:
        """
                
        # Add information for each issue with clear numbering
        for i, issue in enumerate(batch_issues, 1):
            batch_prompt += f"\nISSUE_{i}:\nTitle: {issue.title}\nHTML: {issue.raw_html}\n"
        
        # Call LLM
        response = self.generate_content(batch_prompt)
        
        # Parse response and assign to each issue
        self.parse_batch_response(response, batch_issues)

    def generate_missing_element(self, issue: IssueInfo, context: str) -> str:
        """Generate HTML for missing elements using a compact, targeted prompt.
        Only used when start_line=end_line=0 (insertion required)."""
        title_lower = issue.title.lower()

        # Only handle confirmed missing types
        if 'meta description' in title_lower and 'does not have' in title_lower:
            prompt = (
                "Based on the page context below, write a concise, user-friendly meta description (150-160 characters).\n"
                "Return ONLY a single valid HTML tag like: <meta name=\"description\" content=\"...\">\n"
                "Do NOT include any markdown formatting, code blocks, or explanations.\n"
                "Return ONLY the HTML tag.\n\n"
                f"Context:\n{context}"
            )
            result = self.generate_content(prompt)
            # Clean up any markdown formatting that might have been added
            result = result.strip()
            if result.startswith('```'):
                result = result[3:]
            if result.endswith('```'):
                result = result[:-3]
            if result.startswith('html'):
                result = result[4:]
            result = result.strip()
            return result

        # document title (only if confirmed missing)
        if 'title' in title_lower and 'does not have' in title_lower:
            prompt = (
                "Based on the page context below, write a clear, relevant page title (30-60 characters).\n"
                "Return ONLY a single valid HTML tag like: <title>...</title>\n"
                "Do NOT include any markdown formatting, code blocks, or explanations.\n"
                "Return ONLY the HTML tag.\n\n"
                f"Context:\n{context}"
            )
            result = self.generate_content(prompt)
            # Clean up any markdown formatting
            result = result.strip()
            if result.startswith('```'):
                result = result[3:]
            if result.endswith('```'):
                result = result[:-3]
            if result.startswith('html'):
                result = result[4:]
            result = result.strip()
            return result

        # canonical (only if confirmed missing)
        if 'canonical' in title_lower and 'does not have' in title_lower:
            prompt = (
                "If a canonical URL can be inferred from the context, return a canonical link tag.\n"
                "Return ONLY: <link rel=\"canonical\" href=\"https://example.com/...\">\n"
                "Do NOT include any markdown formatting, code blocks, or explanations.\n"
                "Return ONLY the HTML tag.\n\n"
                f"Context:\n{context}"
            )
            result = self.generate_content(prompt)
            # Clean up any markdown formatting
            result = result.strip()
            if result.startswith('```'):
                result = result[3:]
            if result.endswith('```'):
                result = result[:-3]
            if result.startswith('html'):
                result = result[4:]
            result = result.strip()
            return result

        # viewport (only if confirmed missing)
        if 'viewport' in title_lower and 'does not have' in title_lower:
            return '<meta name="viewport" content="width=device-width, initial-scale=1.0">'

        # html lang (only if confirmed missing)
        if 'lang' in title_lower and 'html' in title_lower and 'does not have' in title_lower:
            return ''

        # default: return original suggestion or empty
        return issue.raw_html or ''

    def parse_batch_response(self, response: str, batch_issues: List[IssueInfo]):
        """Parse batch response and assign fixes to each issue with robust error handling"""
        
        # Clean and normalize the response
        response = response.strip()
        lines = [line.strip() for line in response.split('\n') if line.strip()]
        
        # Track which issues we've successfully parsed
        parsed_issues = set()
        
        for i, issue in enumerate(batch_issues, 1):
            issue_marker = f"ISSUE_{i}:"
            found_fix = False
            
            # Look for the exact issue marker
            for j, line in enumerate(lines):
                if line.startswith(issue_marker):
                    # Extract HTML content after the marker
                    html_content = line[len(issue_marker):].strip()
                    
                    # If HTML is incomplete on this line, collect from subsequent lines
                    if not html_content.startswith('<') or not html_content.endswith('>'):
                        html_lines = [html_content]
                        # Collect HTML from next lines until we hit another ISSUE marker or empty line
                        for k in range(j + 1, len(lines)):
                            next_line = lines[k]
                            if next_line.startswith('ISSUE_') or next_line == '':
                                break
                            html_lines.append(next_line)
                        
                        html_content = ' '.join(html_lines).strip()
                    
                    # Validate that we got actual HTML
                    if html_content.startswith('<') and html_content.endswith('>'):
                        issue.optimized_html = html_content
                        parsed_issues.add(i)
                        found_fix = True
                        print(f"‚úÖ Successfully parsed ISSUE_{i}")
                        break
                    else:
                        print(f"‚ö†Ô∏è  Invalid HTML for ISSUE_{i}: {html_content[:100]}...")
            
            # If no valid fix found, keep original HTML and log warning
            if not found_fix:
                print(f"‚ùå No valid fix found for ISSUE_{i}, keeping original HTML")
                issue.optimized_html = issue.raw_html
        
        # Summary of parsing results
        success_count = len(parsed_issues)
        total_count = len(batch_issues)
        print(f"üìä Batch parsing complete: {success_count}/{total_count} issues successfully parsed")
        
        if success_count < total_count:
            print(f"‚ö†Ô∏è  Warning: {total_count - success_count} issues could not be parsed properly")
            print("Response received:", response[:500] + "..." if len(response) > 500 else response) 
    
    
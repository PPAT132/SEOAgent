# LLM Tool - Core utility for language model interactions
import requests
import json
from ..config import Config

class LLMTool:
    """
    Core tool for interacting with Google's Generative AI API
    """
    
    def __init__(self):
        self.api_key = Config.GOOGLE_API_KEY
        self.validate_config()
    
    def validate_config(self):
        """Validate that required configuration is present"""
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required")
    
    def generate_content(self, prompt: str) -> str:
        """
        Generate content using Google's Generative AI API (Gemini)
        """
        try:
            # Use the correct Google Generative AI API endpoint and headers
            url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
            
            headers = {
                "Content-Type": "application/json",
                "X-goog-api-key": self.api_key
            }
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ]
            }
            
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code != 200:
                response.raise_for_status()
            
            result = response.json()
            
            # Extract the generated content
            if "candidates" in result and len(result["candidates"]) > 0:
                generated_text = result["candidates"][0]["content"]["parts"][0]["text"]
                return generated_text.strip()
            else:
                raise Exception("No content generated by LLM")
                
        except Exception as e:
            raise e 
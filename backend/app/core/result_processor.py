#!/usr/bin/env python3
"""
Result Processor - å¤„ç†åŒ¹é…ç»“æœï¼ŒæŒ‰è¡ŒèŒƒå›´åˆ†ç»„å’Œæ’åº
ç”¨äº LLM æ‰¹é‡å¤„ç†å¤šä¸ªé—®é¢˜
"""

from typing import Any, Dict, List, Tuple
import re


def extract_line_ranges(issues: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    æŒ‰è¡ŒèŒƒå›´åˆ†ç»„é—®é¢˜
    è¿”å›: {"start_line-end_line": [issues]}
    """
    line_ranges = {}
    
    for issue in issues:
        if issue.get("match_status") != "matched":
            continue
            
        start_line = issue.get("match_line_start")
        end_line = issue.get("match_line_end")
        
        if start_line is None or end_line is None:
            continue
            
        # åˆ›å»ºè¡ŒèŒƒå›´é”®
        range_key = f"{start_line}-{end_line}"
        
        if range_key not in line_ranges:
            line_ranges[range_key] = []
        line_ranges[range_key].append(issue)
    
    return line_ranges


def merge_overlapping_ranges(line_ranges: Dict[str, List[Dict[str, Any]]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    åˆå¹¶é‡å æˆ–ç›¸é‚»çš„è¡ŒèŒƒå›´
    ä¾‹å¦‚: 10-20 å’Œ 13-14 åˆå¹¶ä¸º 10-20
    """
    if not line_ranges:
        return {}
    
    # è§£æè¡ŒèŒƒå›´å¹¶æ’åº
    ranges = []
    for range_key, issues in line_ranges.items():
        start, end = map(int, range_key.split('-'))
        ranges.append((start, end, range_key, issues))
    
    # æŒ‰èµ·å§‹è¡Œæ’åº
    ranges.sort(key=lambda x: x[0])
    
    # åˆå¹¶é‡å èŒƒå›´
    merged = []
    current_start, current_end, current_key, current_issues = ranges[0]
    
    for start, end, key, issues in ranges[1:]:
        # å¦‚æœå½“å‰èŒƒå›´ä¸ä¸‹ä¸€ä¸ªèŒƒå›´é‡å æˆ–ç›¸é‚»
        if start <= current_end + 1:
            # æ‰©å±•å½“å‰èŒƒå›´
            current_end = max(current_end, end)
            current_issues.extend(issues)
        else:
            # ä¿å­˜å½“å‰èŒƒå›´ï¼Œå¼€å§‹æ–°èŒƒå›´
            merged.append((current_start, current_end, current_issues))
            current_start, current_end, current_issues = start, end, issues
    
    # æ·»åŠ æœ€åä¸€ä¸ªèŒƒå›´
    merged.append((current_start, current_end, current_issues))
    
    # é‡æ–°æ„å»ºå­—å…¸
    result = {}
    for start, end, issues in merged:
        range_key = f"{start}-{end}"
        result[range_key] = issues
    
    return result


def sort_ranges_by_size(line_ranges: Dict[str, List[Dict[str, Any]]]) -> List[Tuple[str, List[Dict[str, Any]]]]:
    """
    æŒ‰è¡ŒèŒƒå›´å¤§å°æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
    è¿”å›æ’åºåçš„åˆ—è¡¨ï¼Œä¿æŒé¡ºåº
    """
    if not line_ranges:
        return []
    
    # è®¡ç®—æ¯ä¸ªèŒƒå›´çš„è¡Œæ•°å¹¶æ’åº
    sorted_ranges = []
    for range_key, issues in line_ranges.items():
        start, end = map(int, range_key.split('-'))
        line_count = end - start + 1
        sorted_ranges.append((line_count, range_key, issues))
    
    # æŒ‰ç»“æŸè¡Œå·ä»å¤§åˆ°å°æ’åºï¼ˆä¸ºäº†diff checkerä»åå¾€å‰å¤„ç†ï¼‰
    sorted_ranges.sort(key=lambda x: int(x[1].split('-')[1]), reverse=True)
    
    # è¿”å›æ’åºåçš„åˆ—è¡¨
    return [(range_key, issues) for _, range_key, issues in sorted_ranges]


def add_raw_html_context(line_ranges: Dict[str, List[Dict[str, Any]]], html_content: str) -> Dict[str, List[Dict[str, Any]]]:
    """
    ä¸ºæ¯ä¸ªè¡ŒèŒƒå›´æ·»åŠ åŸå§‹HTMLå†…å®¹
    """
    if not html_content:
        return line_ranges
    
    html_lines = html_content.split('\n')
    
    for range_key, issues in line_ranges.items():
        start, end = map(int, range_key.split('-'))
        
        # æå–è¡ŒèŒƒå›´å¯¹åº”çš„HTMLï¼ˆ1-basedåˆ°0-basedè½¬æ¢ï¼‰
        start_idx = max(0, start - 1)
        end_idx = min(len(html_lines), end)
        
        range_html = '\n'.join(html_lines[start_idx:end_idx])
        
        # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ è¡ŒèŒƒå›´HTML
        for issue in issues:
            issue['raw_html'] = range_html
            issue['line_range'] = range_key
    
    return line_ranges


def process_matched_results(matched_result: Dict[str, Any], html_content: str = None) -> Dict[str, Any]:
    """
    å¤„ç†åŒ¹é…ç»“æœï¼Œç”ŸæˆæŒ‰è¡ŒèŒƒå›´åˆ†ç»„çš„æ•°æ®
    """
    issues = matched_result.get("issues", [])
    
    # 1. æŒ‰è¡ŒèŒƒå›´åˆ†ç»„
    line_ranges = extract_line_ranges(issues)
    
    # 2. åˆå¹¶é‡å èŒƒå›´
    merged_ranges = merge_overlapping_ranges(line_ranges)
    
    # 3. æŒ‰å¤§å°æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
    sorted_ranges = sort_ranges_by_size(merged_ranges)
    
    # 4. æ·»åŠ HTMLä¸Šä¸‹æ–‡
    final_ranges = add_raw_html_context(dict(sorted_ranges), html_content)
    
    # 5. ä¸ºæ¯ä¸ªèŒƒå›´çš„é—®é¢˜æŒ‰ç»“æŸè¡Œæ’åºï¼ˆç”¨äºdiffer checkerï¼‰
    for range_key, issues in final_ranges.items():
        issues.sort(key=lambda x: x.get("match_line_end", 0), reverse=True)
    
    return {
        "summary": {
            "total_ranges": len(final_ranges),
            "total_issues": sum(len(issues) for issues in final_ranges.values()),
            "range_sizes": {key: len(issues) for key, issues in final_ranges.items()}
        },
        "line_ranges": final_ranges
    }


def get_line_ranges_for_llm(processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆé€‚åˆLLMå¤„ç†çš„ç®€åŒ–æ ¼å¼
    """
    line_ranges = processed_data.get("line_ranges", {})
    
    llm_inputs = []
    for range_key, issues in line_ranges.items():
        range_info = {
            "line_range": range_key,
            "range_info": {
                "start_line": int(range_key.split('-')[0]),
                "end_line": int(range_key.split('-')[1]),
                "line_count": int(range_key.split('-')[1]) - int(range_key.split('-')[0]) + 1,
                "issue_count": len(issues)
            },
            "issues": []
        }
        
        for issue in issues:
            llm_issue = {
                "audit_id": issue.get("audit_id"),
                "title": issue.get("title"),
                "description": issue.get("description"),
                "match_html": issue.get("match_html"),
                "raw_html": issue.get("raw_html"),
                "match_line_start": issue.get("match_line_start"),
                "match_line_end": issue.get("match_line_end")
            }
            range_info["issues"].append(llm_issue)
        
        llm_inputs.append(range_info)
    
    return llm_inputs


def transform_matched_result(matched_result: Dict[str, Any], html_content: str = None) -> List[Dict[str, Any]]:
    """
    å®Œå…¨é‡æ–°æ ¼å¼åŒ– matched_result
    è¿”å›æ ¼å¼ï¼š
    [
        {
            "start_line": 10,
            "end_line": 20,
            "issue_count": 3,
            "section_html": "å®Œæ•´çš„10-20è¡ŒHTMLå†…å®¹...",
            "issues": [
                {
                    "title": "Links are not crawlable",
                    "raw_html": "<a href=\"javascript:void(0)\">",
                    "start_line": 13,
                    "end_line": 14
                }
            ]
        }
    ]
    """
    print(f"ğŸ”§ transform_matched_result å¼€å§‹å¤„ç†...")
    print(f"   - è¾“å…¥ matched_result å¤§å°: {len(str(matched_result))} å­—ç¬¦")
    print(f"   - HTML å†…å®¹å¤§å°: {len(html_content) if html_content else 0} å­—ç¬¦")
    
    issues = matched_result.get("issues", [])
    print(f"   - åŸå§‹é—®é¢˜æ•°: {len(issues)}")
    
    # ç»Ÿè®¡åŒ¹é…çŠ¶æ€
    matched_issues = [it for it in issues if it.get("match_status") == "matched"]
    unmatched_issues = [it for it in issues if it.get("match_status") != "matched"]
    print(f"   - å·²åŒ¹é…é—®é¢˜: {len(matched_issues)}")
    print(f"   - æœªåŒ¹é…é—®é¢˜: {len(unmatched_issues)}")
    
    if unmatched_issues:
        print(f"   - æœªåŒ¹é…é—®é¢˜ç±»å‹: {[it.get('audit_id') for it in unmatched_issues[:3]]}")
    
    # 1. æŒ‰è¡ŒèŒƒå›´åˆ†ç»„
    print(f"   - å¼€å§‹æŒ‰è¡ŒèŒƒå›´åˆ†ç»„...")
    line_ranges = extract_line_ranges(issues)
    print(f"   - åˆ†ç»„ç»“æœ: {len(line_ranges)} ä¸ªèŒƒå›´")
    for range_key, range_issues in line_ranges.items():
        print(f"     {range_key}: {len(range_issues)} ä¸ªé—®é¢˜")
    
    # 2. åˆå¹¶é‡å èŒƒå›´
    print(f"   - å¼€å§‹åˆå¹¶é‡å èŒƒå›´...")
    merged_ranges = merge_overlapping_ranges(line_ranges)
    print(f"   - åˆå¹¶å: {len(merged_ranges)} ä¸ªèŒƒå›´")
    for range_key, range_issues in merged_ranges.items():
        print(f"     {range_key}: {len(range_issues)} ä¸ªé—®é¢˜")
    
    # 3. æŒ‰å¤§å°æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
    print(f"   - å¼€å§‹æŒ‰å¤§å°æ’åº...")
    sorted_ranges = sort_ranges_by_size(merged_ranges)
    print(f"   - æ’åºåèŒƒå›´: {[range_key for range_key, _ in sorted_ranges]}")
    
    # è¯¦ç»†æ˜¾ç¤ºæ’åºä¿¡æ¯
    print(f"   - æ’åºè¯¦æƒ…:")
    for range_key, issues in sorted_ranges:
        start, end = map(int, range_key.split('-'))
        line_count = end - start + 1
        print(f"     {range_key}: {line_count} è¡Œ")
    
    # 4. é‡æ–°æ ¼å¼åŒ–è¾“å‡º
    print(f"   - å¼€å§‹é‡æ–°æ ¼å¼åŒ–...")
    result = []
    
    # ä¿æŒæ’åºåçš„é¡ºåº
    for range_key, issues in sorted_ranges:
        start_line, end_line = map(int, range_key.split('-'))
        
        # æå–æ•´ä¸ªèŒƒå›´çš„HTMLå†…å®¹
        section_html = ""
        if html_content:
            html_lines = html_content.split('\n')
            start_idx = max(0, start_line - 1)  # 1-basedåˆ°0-basedè½¬æ¢
            end_idx = min(len(html_lines), end_line)
            section_html = '\n'.join(html_lines[start_idx:end_idx])
            print(f"     {range_key}: æå–HTML {len(section_html)} å­—ç¬¦")
        
        # è¿‡æ»¤æ¯ä¸ªissueï¼Œåªä¿ç•™éœ€è¦çš„å­—æ®µ
        filtered_issues = []
        for issue in issues:
            filtered_issue = {
                "title": issue.get("title", ""),
                "raw_html": issue.get("match_html", ""),  # åŒ¹é…åˆ°çš„å…·ä½“HTMLè¡Œ
                "start_line": issue.get("match_line_start"),  # å…·ä½“è¡Œå·
                "end_line": issue.get("match_line_end")
            }
            filtered_issues.append(filtered_issue)
        
        # æŒ‰å…·ä½“è¡Œå·æ’åºï¼ˆç”¨äºdiffer checkerï¼‰
        filtered_issues.sort(key=lambda x: x.get("end_line", 0), reverse=True)
        
        range_info = {
            "start_line": start_line,
            "end_line": end_line,
            "issue_count": len(filtered_issues),
            "section_html": section_html,  # æ•´ä¸ªèŒƒå›´çš„å®Œæ•´HTML
            "issues": filtered_issues
        }
        result.append(range_info)
    
    print(f"   - æœ€ç»ˆè¾“å‡º: {len(result)} ä¸ªèŒƒå›´")
    print(f"ğŸ”§ transform_matched_result å¤„ç†å®Œæˆ")
    
    return result


def create_dummy_matched_result() -> Dict[str, Any]:
    """
    åˆ›å»ºæµ‹è¯•ç”¨çš„ Dummy matched_result æ•°æ®
    åŒ…å«è¡ŒèŒƒå›´é‡å çš„æƒ…å†µæ¥æµ‹è¯•åˆå¹¶é€»è¾‘
    """
    print("ğŸ§ª åˆ›å»º Dummy æµ‹è¯•æ•°æ®...")
    
    dummy_result = {
        "issues": [
            # é—®é¢˜1: 10-16è¡Œ
            {
                "audit_id": "crawlable-anchors",
                "title": "Links are not crawlable",
                "description": "Links with javascript:void(0) are not crawlable",
                "match_status": "matched",
                "match_html": "<a href=\"javascript:void(0)\">click here</a>",
                "match_line_start": 10,
                "match_line_end": 16
            },
            # é—®é¢˜2: 13-20è¡Œ (ä¸é—®é¢˜1é‡å )
            {
                "audit_id": "image-alt",
                "title": "Image elements do not have [alt] attributes",
                "description": "Images without alt attributes are not accessible",
                "match_status": "matched",
                "match_html": "<img src=\"photo.jpg\" class=\"photo\">",
                "match_line_start": 13,
                "match_line_end": 20
            },
            # é—®é¢˜3: 25-30è¡Œ
            {
                "audit_id": "duplicate-title",
                "title": "Document has duplicate title",
                "description": "Duplicate titles can confuse search engines",
                "match_status": "matched",
                "match_html": "<title>Duplicate Title</title>",
                "match_line_start": 25,
                "match_line_end": 30
            },
            # é—®é¢˜4: 28-35è¡Œ (ä¸é—®é¢˜3é‡å )
            {
                "audit_id": "meta-description",
                "title": "Document does not have a meta description",
                "description": "Meta descriptions help with SEO",
                "match_status": "matched",
                "match_html": "<meta name=\"description\" content=\"\">",
                "match_line_start": 28,
                "match_line_end": 35
            },
            # é—®é¢˜5: 40-45è¡Œ (ç‹¬ç«‹èŒƒå›´)
            {
                "audit_id": "hreflang",
                "title": "Document has invalid hreflang",
                "description": "Invalid hreflang attributes",
                "match_status": "matched",
                "match_html": "<link rel=\"alternate\" hreflang=\"xx-YY\">",
                "match_line_start": 40,
                "match_line_end": 45
            },
            # é—®é¢˜6: 50-60è¡Œ (å¤§èŒƒå›´)
            {
                "audit_id": "large-content",
                "title": "Content is too large",
                "description": "Page content exceeds recommended size",
                "match_status": "matched",
                "match_html": "<div class=\"large-content\">...</div>",
                "match_line_start": 50,
                "match_line_end": 60
            },
            # é—®é¢˜7: 55-58è¡Œ (åœ¨é—®é¢˜6èŒƒå›´å†…)
            {
                "audit_id": "small-issue",
                "title": "Small formatting issue",
                "description": "Minor formatting problem",
                "match_status": "matched",
                "match_html": "<span class=\"error\">error</span>",
                "match_line_start": 55,
                "match_line_end": 58
            }
        ]
    }
    
    print(f"âœ… åˆ›å»ºäº† {len(dummy_result['issues'])} ä¸ªæµ‹è¯•é—®é¢˜")
    print("   åŒ…å«ä»¥ä¸‹è¡ŒèŒƒå›´é‡å æƒ…å†µ:")
    print("   - 10-16 å’Œ 13-20 â†’ åº”è¯¥åˆå¹¶ä¸º 10-20")
    print("   - 25-30 å’Œ 28-35 â†’ åº”è¯¥åˆå¹¶ä¸º 25-35") 
    print("   - 50-60 å’Œ 55-58 â†’ åº”è¯¥åˆå¹¶ä¸º 50-60")
    print("   - 40-45 â†’ ç‹¬ç«‹èŒƒå›´")
    
    return dummy_result


def test_dummy_data():
    """
    æµ‹è¯• Dummy æ•°æ®çš„å¤„ç†é€»è¾‘
    """
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯• Dummy æ•°æ®å¤„ç†é€»è¾‘")
    print("="*60)
    
    # åˆ›å»º Dummy æ•°æ®
    dummy_result = create_dummy_matched_result()
    
    # åˆ›å»º Dummy HTML å†…å®¹
    dummy_html = "\n".join([f"Line {i}: Dummy content for testing" for i in range(1, 61)])
    
    # å¤„ç†æ•°æ®
    result = transform_matched_result(dummy_result, dummy_html)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š å¤„ç†ç»“æœ:")
    for i, range_info in enumerate(result, 1):
        print(f"\n{i}. è¡ŒèŒƒå›´: {range_info['start_line']}-{range_info['end_line']}")
        print(f"   é—®é¢˜æ•°é‡: {range_info['issue_count']}")
        print(f"   HTMLé•¿åº¦: {len(range_info['section_html'])} å­—ç¬¦")
        print(f"   å…·ä½“é—®é¢˜:")
        for j, issue in enumerate(range_info['issues'], 1):
            print(f"     {j}. {issue['title']} (è¡Œ {issue['start_line']}-{issue['end_line']})")
            print(f"        HTML: {issue['raw_html']}")
    
    print("\n" + "="*60)
    return result
